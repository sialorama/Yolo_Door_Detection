{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2077,"status":"ok","timestamp":1652728833963,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"YQMv2V2DbLff","outputId":"0c92527e-79d7-46b7-b0b0-197b21f608cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Monter le stockage dans Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8552,"status":"ok","timestamp":1652728842510,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"iTqVPBLf9GXP"},"outputs":[],"source":["# Imports\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import inspect\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1652728842512,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"3zM1nn-E9KU8"},"outputs":[],"source":["# Set batch size for training and validation\n","batch_size = 32\n","num_classes = 3\n","num_iterations = 34"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1652728842513,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"MIFoQx3hJ4SJ"},"outputs":[],"source":["# List all available models\n","model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1652728842514,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"DgwH3gozahgI"},"outputs":[],"source":["# Chemin d'accès dans Colab\n","train = '/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/data/Cropped/RGB/train'\n","test = '/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/data/Cropped/RGB/test'\n","validation = '/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/data/Cropped/RGB/val'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1652728842515,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"IT0o4Q9PFZe9"},"outputs":[],"source":["# # Chemin d'accès en local\n","# train = \"./data/Cropped/RGB/train\"\n","# test = \"./data/Cropped/RGB/test\"\n","# validation = \"./data/Cropped/RGB/val\""]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7973,"status":"ok","timestamp":1652728850475,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"lfyGdn_cKOoP","outputId":"4e786107-4e97-4ff3-993c-181cfeb27673"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1086 files belonging to 3 classes.\n","Found 60 files belonging to 3 classes.\n","Found 60 files belonging to 3 classes.\n"]}],"source":["train_ds = tf.keras.utils.image_dataset_from_directory(train, seed=5, batch_size=batch_size)\n","test_ds = tf.keras.utils.image_dataset_from_directory(test, seed=5, batch_size=batch_size)\n","val_ds = tf.keras.utils.image_dataset_from_directory(validation, seed=5, batch_size=batch_size)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1652728850826,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"h1Uqz4vCFZe-","outputId":"cef8cd53-7dc6-4651-f360-47f7445fc986"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'Semi': 0, 'Open': 1, 'Closed': 2}\n","['Semi', 'Open', 'Closed']\n","[0, 1, 2]\n"]}],"source":["# Afficher des les classes et leurs labels\n","import os\n","categories=os.listdir(train)\n","labels=[i for i in range(len(categories))]\n","\n","label_dict=dict(zip(categories,labels))\n","\n","print(label_dict)\n","print(categories)\n","print(labels)\n","\n","img_size=100\n","data=[]\n","target=[]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":418,"status":"ok","timestamp":1652728851239,"user":{"displayName":"Jamal IBANNI","userId":"09763867100996115822"},"user_tz":-120},"id":"auoxO--7iS_a"},"outputs":[],"source":["def normalize_img(image, label, img_size):\n","    # Resize image to the desired img_size and normalize it\n","    # One hot encode the label\n","    image = tf.image.resize(image, img_size)\n","    image = tf.cast(image, tf.float32) / 255.\n","    label = tf.one_hot(label, depth=num_classes)\n","    return image, label\n","    \n","def preprocess_data(train, validation, batch_size, img_size):\n","    # Apply the normalize_img function on all train and validation data and create batches\n","    train_processed = train.map(lambda image, label: normalize_img(image, label, img_size))\n","    \n","    # If your data is already batched (eg, when using the image_dataset_from_directory function), remove .batch(batch_size)\n","    train_processed = train_processed.repeat()\n","    \n","    validation_processed = validation.map(lambda image, label: normalize_img(image, label, img_size))\n","    \n","    # If your data is already batched (eg, when using the image_dataset_from_directory function), remove .batch(batch_size)\n","    validation_processed = validation_processed\n","    \n","    return train_processed, validation_processed\n","    \n","# Run preprocessing\n","train_processed_224, validation_processed_224 = preprocess_data(train_ds, val_ds, batch_size, img_size=[224,224])\n","train_processed_331, validation_processed_331 = preprocess_data(train_ds, val_ds, batch_size, img_size=[331,331])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"8llLDwhiKdTG"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/35 [00:00\u003c?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n","29089792/29084464 [==============================] - 0s 0us/step\n","29097984/29084464 [==============================] - 0s 0us/step\n","Epoch 1/10\n","34/34 [==============================] - 253s 6s/step - loss: 0.7431 - accuracy: 0.7145 - val_loss: 1.0563 - val_accuracy: 0.6167\n","Epoch 2/10\n","34/34 [==============================] - 181s 5s/step - loss: 0.5060 - accuracy: 0.8444 - val_loss: 0.7486 - val_accuracy: 0.6500\n","Epoch 3/10\n","34/34 [==============================] - 183s 5s/step - loss: 0.4104 - accuracy: 0.8674 - val_loss: 0.7394 - val_accuracy: 0.6333\n","Epoch 4/10\n","34/34 [==============================] - 179s 5s/step - loss: 0.3536 - accuracy: 0.8794 - val_loss: 0.6822 - val_accuracy: 0.6500\n","Epoch 5/10\n","34/34 [==============================] - 181s 5s/step - loss: 0.3118 - accuracy: 0.8923 - val_loss: 0.5186 - val_accuracy: 0.7333\n","Epoch 6/10\n","34/34 [==============================] - 184s 5s/step - loss: 0.2837 - accuracy: 0.9015 - val_loss: 0.6014 - val_accuracy: 0.7167\n","Epoch 7/10\n","34/34 [==============================] - 184s 5s/step - loss: 0.2571 - accuracy: 0.9061 - val_loss: 0.5178 - val_accuracy: 0.7333\n","Epoch 8/10\n","34/34 [==============================] - 176s 5s/step - loss: 0.2370 - accuracy: 0.9227 - val_loss: 0.4956 - val_accuracy: 0.7833\n","Epoch 9/10\n","34/34 [==============================] - 184s 5s/step - loss: 0.2185 - accuracy: 0.9263 - val_loss: 0.5273 - val_accuracy: 0.7500\n","Epoch 10/10\n","34/34 [==============================] - 180s 5s/step - loss: 0.2023 - accuracy: 0.9355 - val_loss: 0.4466 - val_accuracy: 0.8000\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 1/35 [31:44\u003c17:59:12, 1904.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n","51879936/51877672 [==============================] - 0s 0us/step\n","51888128/51877672 [==============================] - 0s 0us/step\n","Epoch 1/10\n","34/34 [==============================] - 238s 7s/step - loss: 0.8086 - accuracy: 0.6832 - val_loss: 1.0257 - val_accuracy: 0.6167\n","Epoch 2/10\n","34/34 [==============================] - 217s 6s/step - loss: 0.5192 - accuracy: 0.8177 - val_loss: 0.6944 - val_accuracy: 0.6667\n","Epoch 3/10\n","34/34 [==============================] - 220s 6s/step - loss: 0.3976 - accuracy: 0.8665 - val_loss: 0.6101 - val_accuracy: 0.7167\n","Epoch 4/10\n","34/34 [==============================] - 223s 7s/step - loss: 0.3266 - accuracy: 0.8913 - val_loss: 0.5256 - val_accuracy: 0.7500\n","Epoch 5/10\n","34/34 [==============================] - 221s 6s/step - loss: 0.2816 - accuracy: 0.9079 - val_loss: 0.4932 - val_accuracy: 0.7667\n","Epoch 6/10\n","34/34 [==============================] - 222s 6s/step - loss: 0.2409 - accuracy: 0.9190 - val_loss: 0.4719 - val_accuracy: 0.7833\n","Epoch 7/10\n","34/34 [==============================] - 216s 6s/step - loss: 0.2101 - accuracy: 0.9346 - val_loss: 0.5404 - val_accuracy: 0.7333\n","Epoch 8/10\n","21/34 [=================\u003e............] - ETA: 1:18 - loss: 0.1863 - accuracy: 0.9464"]}],"source":["# Loop over each model available in Keras\n","model_benchmarks = {'model_name': [], 'num_model_params': [], 'validation_accuracy': []}\n","\n","for model_name, model in tqdm(model_dictionary.items()):\n","    # Special handling for \"NASNetLarge\" since it requires input images with size (331,331)\n","    if 'NASNetLarge' in model_name:\n","        input_shape=(331,331,3)\n","        train_processed = train_processed_331\n","        validation_processed = validation_processed_331\n","    else:\n","        input_shape=(224,224,3)\n","        train_processed = train_processed_224\n","        validation_processed = validation_processed_224\n","        \n","    # load the pre-trained model with global average pooling as the last layer and freeze the model weights\n","    pre_trained_model = model(include_top=False, pooling='avg', input_shape=input_shape)\n","    pre_trained_model.trainable = False\n","    \n","    # custom modifications on top of pre-trained model and fit\n","    clf_model = tf.keras.models.Sequential()\n","    clf_model.add(pre_trained_model)\n","    clf_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n","    clf_model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n","    history = clf_model.fit(train_processed, epochs=10, validation_data=validation_processed, steps_per_epoch=num_iterations)\n","    \n","    # Calculate all relevant metrics\n","    model_benchmarks['model_name'].append(model_name)\n","    model_benchmarks['num_model_params'].append(pre_trained_model.count_params())\n","    model_benchmarks['validation_accuracy'].append(history.history['val_accuracy'][-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb5Gc7NpKfYp"},"outputs":[],"source":["# Convert Results to DataFrame for easy viewing\n","benchmark_df = pd.DataFrame(model_benchmarks)\n","\n","# sort in ascending order of num_model_params column\n","benchmark_df.sort_values('num_model_params', inplace=True)\n","\n","# write results to csv file\n","benchmark_df.to_csv('benchmark_df.csv', index=False)\n","# benchmark_df\n","\n","# # benchmark_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/benchmark_df.csv')\n","# benchmark_df = pd.read_csv('benchmark_df.csv')\n","# benchmark_df.sort_values(by=['validation_accuracy'], inplace=True, ascending=False)\n","# benchmark_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiDjgc7VJddz"},"outputs":[],"source":["# Sauvegarder le dataframe du Benchmark des models\n","benchmark_df.to_csv('benchmark_df.csv', index=False)\n","benchmark_df.sort_values(by=['validation_accuracy'], inplace=True, ascending=False)\n","benchmark_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_v1hp4U0j86F"},"outputs":[],"source":["# # Sauvegarder le dataframe du Benchmark des models\n","# from google.colab import files\n","# files.download(\"benchmark_df.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnAPIk_ZTtz3"},"outputs":[],"source":["# Loop over each row and plot the num_model_params vs validation_accuracy\n","markers=[\".\",\",\",\"o\",\"v\",\"^\",\"\u003c\",\"\u003e\",\"1\",\"2\",\"3\",\"4\",\"8\",\"s\",\"p\",\"P\",\"*\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\",4,5,6,7,8,9,10,11]\n","plt.figure(figsize=(7,5))\n","\n","for row in benchmark_df[0:5].itertuples():\n","    plt.scatter(row.num_model_params, row.validation_accuracy, label=row.model_name, marker=markers[row.Index], s=150, linewidths=0)\n","    \n","plt.xscale('log')\n","plt.xlabel('Number of Parameters in Model')\n","plt.ylabel('Validation Accuracy after 3 Epochs')\n","plt.title('Accuracy vs Model Size')\n","\n","# Move legend out of the plot\n","plt.legend(bbox_to_anchor=(1, 1), loc='upper left');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoWZ71v6LIj2"},"outputs":[],"source":["# Loop over each row and plot the num_model_params vs validation_accuracy\n","\n","plt.figure(figsize=(10,8))\n","\n","for row in benchmark_df.itertuples():\n","    plt.scatter(row.num_model_params, row.validation_accuracy, label=row.model_name, s=150)\n","    \n","plt.xscale('log')\n","plt.xlabel('Number of Parameters in Model')\n","plt.ylabel('Validation Accuracy after 10 Epochs')\n","plt.title('Accuracy vs Model Size')\n","\n","# Move legend out of the plot\n","plt.legend(bbox_to_anchor=(1, 1), loc='upper left');"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYgWiqcqnp7e"},"outputs":[],"source":["# importation de MobileNet\n","\n","mobilenet = tf.keras.applications.mobilenet.MobileNet(\n","    input_shape=None, alpha=1.0, depth_multiplier=1, dropout=0.001,\n","    include_top=True, weights='imagenet', input_tensor=None, pooling=None,\n","    classes=1000, classifier_activation='softmax'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uGKIV-3j7371"},"outputs":[],"source":["# Compile model\n","mobilenet.compile(\n","      optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n","          loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-h10fAKpuZS"},"outputs":[],"source":["model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n","    input_shape=(224,224,3), include_top=True, weights='imagenet', pooling=\"avg\",\n","    classifier_activation='softmax'\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKYLpDZYFZfJ"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Kx1UiYdFZfJ"},"outputs":[],"source":["plt.plot(history.history['loss'],'r',label='training loss')\n","plt.plot(history.history['val_loss'],label='validation loss')\n","plt.xlabel('# epochs')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/history.png')\n","plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/history.pdf')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yU_m3DXhoM_v"},"outputs":[],"source":["plt.plot(history.history['accuracy'],'r',label='training accuracy')\n","plt.plot(history.history['val_accuracy'],label='validation accuracy')\n","plt.xlabel('# epochs')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/accuracy.png')\n","plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/accuracy.pdf')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6OmAZvcITtz6"},"outputs":[],"source":["model.summary()"]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"name":"02.classification_Portes - Colab.ipynb","version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}