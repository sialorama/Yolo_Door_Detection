{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4267,
     "status": "ok",
     "timestamp": 1652722802890,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "YQMv2V2DbLff",
    "outputId": "334e236e-56e8-43b8-c713-6c522a43d230"
   },
   "outputs": [],
   "source": [
    "# # Monter le stockage dans Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4203,
     "status": "ok",
     "timestamp": 1652722809292,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "iTqVPBLf9GXP"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1652722809293,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "3zM1nn-E9KU8"
   },
   "outputs": [],
   "source": [
    "# Set batch size for training and validation\n",
    "batch_size = 32\n",
    "num_classes = 3\n",
    "num_iterations = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 750,
     "status": "ok",
     "timestamp": 1652722866144,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "MIFoQx3hJ4SJ"
   },
   "outputs": [],
   "source": [
    "# List all available models\n",
    "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652722866691,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "DgwH3gozahgI"
   },
   "outputs": [],
   "source": [
    "# # Chemin d'accès dans Colab\n",
    "# train = '/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/data/Cropped/RGB/train'\n",
    "# test = '/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/data/Cropped/RGB/test'\n",
    "# validation = '/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/data/Cropped/RGB/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1652722868667,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "IT0o4Q9PFZe9"
   },
   "outputs": [],
   "source": [
    "# Chemin d'accès en local\n",
    "train = \"./data/Cropped/RGB/train\"\n",
    "test = \"./data/Cropped/RGB/test\"\n",
    "validation = \"./data/Cropped/RGB/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1189,
     "status": "ok",
     "timestamp": 1652709034133,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "lfyGdn_cKOoP",
    "outputId": "3db33d1a-8520-4d8f-d34c-0b384672763d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1086 files belonging to 3 classes.\n",
      "Found 60 files belonging to 3 classes.\n",
      "Found 60 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(train, seed=5, batch_size=batch_size)\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(test, seed=5, batch_size=batch_size)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(validation, seed=5, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3922,
     "status": "ok",
     "timestamp": 1652722873399,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "h1Uqz4vCFZe-",
    "outputId": "7aeeb393-f9be-4ea6-8d50-95725cab6afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Semi': 0, 'Open': 1, 'Closed': 2}\n",
      "['Semi', 'Open', 'Closed']\n",
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Afficher des les classes et leurs labels\n",
    "import os\n",
    "categories=os.listdir(train)\n",
    "labels=[i for i in range(len(categories))]\n",
    "\n",
    "label_dict=dict(zip(categories,labels))\n",
    "\n",
    "print(label_dict)\n",
    "print(categories)\n",
    "print(labels)\n",
    "\n",
    "img_size=100\n",
    "data=[]\n",
    "target=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object of type 'tuple' to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train:\n\u001b[1;32m----> 5\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     im_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(im, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), interpolation\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR)\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(im_resized, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert object of type 'tuple' to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in train:\n",
    "    im = cv2.imread(i)\n",
    "    im_resized = cv2.resize(im, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(im_resized, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "auoxO--7iS_a"
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label, img_size):\n",
    "    # Resize image to the desired img_size and normalize it\n",
    "    # One hot encode the label\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "    \n",
    "def preprocess_data(train, validation, batch_size, img_size):\n",
    "    # Apply the normalize_img function on all train and validation data and create batches\n",
    "    train_processed = train.map(lambda image, label: normalize_img(image, label, img_size))\n",
    "    \n",
    "    # If your data is already batched (eg, when using the image_dataset_from_directory function), remove .batch(batch_size)\n",
    "    train_processed = train_processed.repeat()\n",
    "    \n",
    "    validation_processed = validation.map(lambda image, label: normalize_img(image, label, img_size))\n",
    "    \n",
    "    # If your data is already batched (eg, when using the image_dataset_from_directory function), remove .batch(batch_size)\n",
    "    validation_processed = validation_processed\n",
    "    \n",
    "    return train_processed, validation_processed\n",
    "    \n",
    "# Run preprocessing\n",
    "train_processed_224, validation_processed_224 = preprocess_data(train_ds, val_ds, batch_size, img_size=[224,224])\n",
    "train_processed_331, validation_processed_331 = preprocess_data(train_ds, val_ds, batch_size, img_size=[331,331])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8llLDwhiKdTG",
    "outputId": "54e67af6-4cd2-4342-ad9a-1ece8719c7ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 135s 4s/step - loss: 0.6847 - accuracy: 0.7422 - val_loss: 0.9703 - val_accuracy: 0.6167\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 139s 4s/step - loss: 0.4879 - accuracy: 0.8287 - val_loss: 0.6989 - val_accuracy: 0.6667\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 123s 4s/step - loss: 0.3982 - accuracy: 0.8554 - val_loss: 0.6822 - val_accuracy: 0.6833\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 141s 4s/step - loss: 0.3460 - accuracy: 0.8858 - val_loss: 0.6287 - val_accuracy: 0.6833\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 132s 4s/step - loss: 0.3054 - accuracy: 0.8987 - val_loss: 0.4879 - val_accuracy: 0.7667\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 130s 4s/step - loss: 0.2778 - accuracy: 0.9061 - val_loss: 0.5634 - val_accuracy: 0.7333\n",
      "Epoch 7/10\n",
      "19/34 [===============>..............] - ETA: 53s - loss: 0.2590 - accuracy: 0.9227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 0/35 [14:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m clf_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m clf_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 24\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mclf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate all relevant metrics\u001b[39;00m\n\u001b[0;32m     27\u001b[0m model_benchmarks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_name)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over each model available in Keras\n",
    "model_benchmarks = {'model_name': [], 'num_model_params': [], 'validation_accuracy': []}\n",
    "\n",
    "for model_name, model in tqdm(model_dictionary.items()):\n",
    "    # Special handling for \"NASNetLarge\" since it requires input images with size (331,331)\n",
    "    if 'NASNetLarge' in model_name:\n",
    "        input_shape=(331,331,3)\n",
    "        train_processed = train_processed_331\n",
    "        validation_processed = validation_processed_331\n",
    "    else:\n",
    "        input_shape=(224,224,3)\n",
    "        train_processed = train_processed_224\n",
    "        validation_processed = validation_processed_224\n",
    "        \n",
    "    # load the pre-trained model with global average pooling as the last layer and freeze the model weights\n",
    "    pre_trained_model = model(include_top=False, pooling='avg', input_shape=input_shape)\n",
    "    pre_trained_model.trainable = False\n",
    "    \n",
    "    # custom modifications on top of pre-trained model and fit\n",
    "    clf_model = tf.keras.models.Sequential()\n",
    "    clf_model.add(pre_trained_model)\n",
    "    clf_model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "    clf_model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = clf_model.fit(train_processed, epochs=10, validation_data=validation_processed, steps_per_epoch=num_iterations)\n",
    "    \n",
    "    # Calculate all relevant metrics\n",
    "    model_benchmarks['model_name'].append(model_name)\n",
    "    model_benchmarks['num_model_params'].append(pre_trained_model.count_params())\n",
    "    model_benchmarks['validation_accuracy'].append(history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "executionInfo": {
     "elapsed": 455,
     "status": "error",
     "timestamp": 1652722790330,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "fb5Gc7NpKfYp",
    "outputId": "aacb8c22-8ed0-4f74-985a-5b674bffa3f8"
   },
   "outputs": [],
   "source": [
    "# Convert Results to DataFrame for easy viewing\n",
    "benchmark_df = pd.DataFrame(model_benchmarks)\n",
    "\n",
    "# sort in ascending order of num_model_params column\n",
    "benchmark_df.sort_values('num_model_params', inplace=True)\n",
    "\n",
    "# write results to csv file\n",
    "benchmark_df.to_csv('benchmark_df.csv', index=False)\n",
    "# benchmark_df\n",
    "\n",
    "# # benchmark_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/benchmark_df.csv')\n",
    "# benchmark_df = pd.read_csv('benchmark_df.csv')\n",
    "# benchmark_df.sort_values(by=['validation_accuracy'], inplace=True, ascending=False)\n",
    "# benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiDjgc7VJddz"
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le dataframe du Benchmark des models\n",
    "benchmark_df.to_csv('benchmark_df.csv', index=False)\n",
    "benchmark_df.sort_values(by=['validation_accuracy'], inplace=True, ascending=False)\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_v1hp4U0j86F"
   },
   "outputs": [],
   "source": [
    "# # Sauvegarder le dataframe du Benchmark des models\n",
    "# from google.colab import files\n",
    "# files.download(\"benchmark_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each row and plot the num_model_params vs validation_accuracy\n",
    "markers=[\".\",\",\",\"o\",\"v\",\"^\",\"<\",\">\",\"1\",\"2\",\"3\",\"4\",\"8\",\"s\",\"p\",\"P\",\"*\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\",4,5,6,7,8,9,10,11]\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "for row in benchmark_df[0:5].itertuples():\n",
    "    plt.scatter(row.num_model_params, row.validation_accuracy, label=row.model_name, marker=markers[row.Index], s=150, linewidths=0)\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of Parameters in Model')\n",
    "plt.ylabel('Validation Accuracy after 3 Epochs')\n",
    "plt.title('Accuracy vs Model Size')\n",
    "\n",
    "# Move legend out of the plot\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 427,
     "status": "error",
     "timestamp": 1652721663395,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "WoWZ71v6LIj2",
    "outputId": "2e630b4a-ff16-494c-c54f-2b0ff842e160"
   },
   "outputs": [],
   "source": [
    "# Loop over each row and plot the num_model_params vs validation_accuracy\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for row in benchmark_df.itertuples():\n",
    "    plt.scatter(row.num_model_params, row.validation_accuracy, label=row.model_name, s=150)\n",
    "    \n",
    "plt.xscale('log')\n",
    "plt.xlabel('Number of Parameters in Model')\n",
    "plt.ylabel('Validation Accuracy after 10 Epochs')\n",
    "plt.title('Accuracy vs Model Size')\n",
    "\n",
    "# Move legend out of the plot\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "error",
     "timestamp": 1652722491341,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "HYgWiqcqnp7e",
    "outputId": "58af827c-afe9-428b-e64f-c99d382c5171"
   },
   "outputs": [],
   "source": [
    "# importation de MobileNet\n",
    "\n",
    "mobilenet = tf.keras.applications.mobilenet.MobileNet(\n",
    "    input_shape=None, alpha=1.0, depth_multiplier=1, dropout=0.001,\n",
    "    include_top=True, weights='imagenet', input_tensor=None, pooling=None,\n",
    "    classes=1000, classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGKIV-3j7371"
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "mobilenet.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 1725,
     "status": "error",
     "timestamp": 1652710644827,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "Q-h10fAKpuZS",
    "outputId": "df226fd7-c6cd-4ff5-8517-2d72c1b733ef"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape=(224,224,3), include_top=True, weights='imagenet', pooling=\"avg\",\n",
    "    classifier_activation='softmax'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKYLpDZYFZfJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "error",
     "timestamp": 1652710500578,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "7Kx1UiYdFZfJ",
    "outputId": "1ed38c72-8007-4eef-e8cc-bdd9d9a3bb0b"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'r',label='training loss')\n",
    "plt.plot(history.history['val_loss'],label='validation loss')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/history.png')\n",
    "plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/history.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "error",
     "timestamp": 1652711067172,
     "user": {
      "displayName": "Jamal IBANNI",
      "userId": "09763867100996115822"
     },
     "user_tz": -120
    },
    "id": "yU_m3DXhoM_v",
    "outputId": "d2deb5a2-a358-492f-b899-0c2d53607e23"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],'r',label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/accuracy.png')\n",
    "plt.savefig('/content/drive/MyDrive/Colab Notebooks/00.Cas_pratique_ia/captures/accuracy.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Krw7pZJTFZfK"
   },
   "outputs": [],
   "source": [
    "print(model.evaluate(test_data,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "02.classification_Portes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
